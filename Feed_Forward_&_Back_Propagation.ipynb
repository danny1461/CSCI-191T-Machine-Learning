{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feed Forward & Back Propagation",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNFUbQhij2VV8qxxZOT4vfz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danny1461/CSCI-191T-Machine-Learning/blob/main/Feed_Forward_%26_Back_Propagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGAY5ihZY44x"
      },
      "source": [
        "# Feed Forward & Back Propagation\n",
        "By Daniel Flynn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EHDlJZab_Lj"
      },
      "source": [
        "import random\n",
        "import math\n",
        "\n",
        "def linearSum(weights, inputs):\n",
        "  return sum([w*i for w, i in zip(weights, inputs)])\n",
        "\n",
        "def logisticalRegression(weights, inputs):\n",
        "  return 1.0 / (1.0 + math.e ** (-linearSum(weights, inputs)))\n",
        "\n",
        "class Node():\n",
        "  def __init__(self, inputCount):\n",
        "    self.alg = logisticalRegression\n",
        "    self.weights = [random.uniform(-0.1, 0.1) for i in range(inputCount + 1)]\n",
        "\n",
        "  def getOutput(self, inputs):\n",
        "    self.output = self.alg(self.weights, inputs)\n",
        "    return self.output\n",
        "\n",
        "class Graph:\n",
        "  def __init__(self, layers):\n",
        "    self.layers = []\n",
        "    self.deltas = []\n",
        "    for i in range(len(layers) - 1):\n",
        "      self.layers.append([ Node(layers[i]) for j in range(layers[i + 1]) ])\n",
        "      self.deltas.append([0] * layers[i + 1])\n",
        "    self.outputNdx = len(self.layers) - 1\n",
        "\n",
        "  def getOutput(self, inputs):\n",
        "    for layer in self.layers:\n",
        "      inputs = [ node.getOutput([1] + inputs) for node in layer ]\n",
        "\n",
        "    return inputs\n",
        "\n",
        "  def calculateDeltas(self, expected):\n",
        "    for i in reversed(range(len(self.layers))):\n",
        "      layer = self.layers[i]\n",
        "\n",
        "      if i == self.outputNdx:\n",
        "        errors = [node.output - r for node, r in zip(layer, expected)]\n",
        "      else:\n",
        "        errors = []\n",
        "        for j in range(len(layer)):\n",
        "          error = 0.0\n",
        "          for k in range(len(self.layers[i + 1])):\n",
        "            error += self.layers[i + 1][k].weights[j + 1] * self.deltas[i + 1][k]\n",
        "          errors.append(error)\n",
        "\n",
        "      for j in range(len(layer)):\n",
        "        node = layer[j]\n",
        "        self.deltas[i][j] = errors[j] * node.output * (1.0 - node.output)\n",
        "\n",
        "  def updateWeights(self, inputs, learningRate):\n",
        "    for i in range(len(self.layers)):\n",
        "      if i > 0:\n",
        "        inputs = [node.output for node in self.layers[i - 1]]\n",
        "        \n",
        "      inputs = [1] + inputs\n",
        "      for j in range(len(self.layers[i])):\n",
        "        for k in range(len(inputs)):\n",
        "          self.layers[i][j].weights[k] -= learningRate * self.deltas[i][j] * inputs[k]\n",
        "\n",
        "  def train(self, trainingSet, learningRate = 0.5, learningThreshhold = 0.000001, displayRegularity = 1000, displayFn = None):\n",
        "    last_error = 0\n",
        "    error = float('inf')\n",
        "    iterations = 0\n",
        "    while last_error - error > learningThreshhold or math.isinf(error):\n",
        "      last_error = error;\n",
        "\n",
        "      error = 0\n",
        "      for inputs, expected in trainingSet:\n",
        "        outputs = self.getOutput(inputs)\n",
        "\n",
        "        error += sum([(expected[i] - outputs[i])**2 for i in range(len(expected))])\n",
        "        self.calculateDeltas(expected)\n",
        "        self.updateWeights(inputs, learningRate)\n",
        "      \n",
        "      iterations += 1\n",
        "      if iterations % displayRegularity == 0:\n",
        "        print('Iteration {}: Error = {}'.format(iterations, error))\n",
        "        if displayFn != None:\n",
        "          displayFn()\n",
        "\n",
        "    if iterations % displayRegularity != 0:\n",
        "      print('Iteration {}: Error = {}'.format(iterations, error))\n",
        "      if displayFn != None:\n",
        "        displayFn()\n",
        "\n",
        "def evaluateGraph(graph, trainingSet):\n",
        "    stats = {}\n",
        "    error = 0\n",
        "    for inputs, expected in trainingSet:\n",
        "      outputs = g.getOutput(inputs)\n",
        "      error += sum([(expected[i] - outputs[i])**2 for i in range(len(expected))])\n",
        "      key = (expected[0], 1 if outputs[0] >= 0.5 else 0)\n",
        "      stats[key] = stats.get(key, 0) + 1\n",
        "    \n",
        "    print('Recal:', stats.get((1, 1), 0) / (stats.get((1, 1), 0) + stats.get((1, 0), 0)))\n",
        "    print('Precision:', stats.get((1, 1), 0) / (stats.get((1, 1), 0) + stats.get((0, 1), 0)))\n",
        "    print('')\n",
        "\n",
        "def printGraph(graph, key = 'weights'):\n",
        "  label = key.capitalize()\n",
        "  for i in range(len(graph.layers[0])):\n",
        "    print('w{} {}: '.format(i + 1, label), getattr(graph.layers[0][i], key))\n",
        "  for i in range(len(graph.layers[1])):\n",
        "    print('y{} {}: '.format(i + 1, label), getattr(graph.layers[1][i], key))"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWzG4K2Dc_Qd",
        "outputId": "6c468925-6484-47e2-ad68-33269fa21862"
      },
      "source": [
        "random.seed(2021)\n",
        "\n",
        "# 2 Input Nodes\n",
        "# 2 Hidden Nodes\n",
        "# 1 Output Node\n",
        "g = Graph([2, 2, 1])\n",
        "\n",
        "print('Starting State...')\n",
        "printGraph(g)\n",
        "print('')\n",
        "\n",
        "trainingData = [\n",
        "  ( [0, 0], [0] ),\n",
        "  ( [0, 1], [1] ),\n",
        "  ( [1, 0], [1] ),\n",
        "  ( [1, 1], [0] ),\n",
        "]\n",
        "\n",
        "g.train(trainingData, displayFn = lambda: evaluateGraph(g, trainingData))\n",
        "print('Final State...')\n",
        "printGraph(g)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting State...\n",
            "w1 Weights:  [0.06726750046641483, 0.07166048084163751, 0.008822066004144327]\n",
            "w2 Weights:  [-0.05053353327699653, 0.027004118315371473, 0.09472637093585565]\n",
            "y1 Weights:  [-0.0052418342615191404, -0.08725176406969695, -0.04601109132754114]\n",
            "\n",
            "Iteration 1000: Error = 1.0315529244237684\n",
            "Recal: 0.5\n",
            "Precision: 0.5\n",
            "\n",
            "Iteration 2000: Error = 0.7041606836014094\n",
            "Recal: 1.0\n",
            "Precision: 0.6666666666666666\n",
            "\n",
            "Iteration 3000: Error = 0.02666396980633983\n",
            "Recal: 1.0\n",
            "Precision: 1.0\n",
            "\n",
            "Iteration 4000: Error = 0.008288459484369187\n",
            "Recal: 1.0\n",
            "Precision: 1.0\n",
            "\n",
            "Iteration 5000: Error = 0.004761404737942236\n",
            "Recal: 1.0\n",
            "Precision: 1.0\n",
            "\n",
            "Iteration 6000: Error = 0.00330913665554861\n",
            "Recal: 1.0\n",
            "Precision: 1.0\n",
            "\n",
            "Iteration 6034: Error = 0.0032748063687582443\n",
            "Recal: 1.0\n",
            "Precision: 1.0\n",
            "\n",
            "Final State...\n",
            "w1 Weights:  [2.575335903705313, -6.477063954334737, -6.500597376693722]\n",
            "w2 Weights:  [6.48388163444038, -4.378804740383171, -4.38084896165839]\n",
            "y1 Weights:  [-4.166028593693109, -9.012724897902848, 8.886851138845214]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_x6jMYbaPaX"
      },
      "source": [
        "In this case, we're able to get convergence. But I have seen some random starting weights that seem to never converge. I'm not sure if that's because my learning rate is too high or if there is a local minimum there that the code can't get out of.\n",
        "\n",
        "So as it happens, my starting seed of the current year (2021) succeeds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbpa8f7-b4Ov"
      },
      "source": [
        "### Graph state for each input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRoRG103b0GS",
        "outputId": "b3d77c61-a1da-4d54-f399-7c8fb45afc15"
      },
      "source": [
        "log = True\n",
        "for inputs, expected in trainingData:\n",
        "  print('Inputs: ', inputs)\n",
        "  g.getOutput(inputs)\n",
        "  print('Graph State...')\n",
        "  printGraph(g, key = 'output')\n",
        "  print('Expected Output: ', expected)\n",
        "  print('')"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:  [0, 0]\n",
            "Graph State...\n",
            "w1 Output:  0.9292572730308457\n",
            "w2 Output:  0.9984744622939888\n",
            "y1 Output:  0.02489508095471664\n",
            "Expected Output:  [0]\n",
            "\n",
            "Inputs:  [0, 1]\n",
            "Graph State...\n",
            "w1 Output:  0.019354967001063178\n",
            "w2 Output:  0.8911975892963746\n",
            "y1 Output:  0.9728663147768487\n",
            "Expected Output:  [1]\n",
            "\n",
            "Inputs:  [1, 0]\n",
            "Graph State...\n",
            "w1 Output:  0.01980672877570542\n",
            "w2 Output:  0.8913956476249763\n",
            "y1 Output:  0.9728052306072238\n",
            "Expected Output:  [1]\n",
            "\n",
            "Inputs:  [1, 1]\n",
            "Graph State...\n",
            "w1 Output:  3.0360874889983035e-05\n",
            "w2 Output:  0.09314948399027904\n",
            "y1 Output:  0.034273883186918354\n",
            "Expected Output:  [0]\n",
            "\n"
          ]
        }
      ]
    }
  ]
}