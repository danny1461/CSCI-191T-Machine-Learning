{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment-03-linear-logistic-regression",
      "provenance": [],
      "collapsed_sections": [
        "Cjbv6GlPvFWh",
        "cEc144r8FWGh",
        "uH7PQswEHYr7",
        "lHnHI8c99zHo",
        "C42GontTPMSV",
        "f76EZDmkmzkc",
        "nLd4imDcoEqr"
      ],
      "authorship_tag": "ABX9TyPsNnYsEYBY10IuiOU2ozuk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danny1461/CSCI-191T-Machine-Learning/blob/main/assignment_03_linear_logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRdjQry9sOiM"
      },
      "source": [
        "# Linear & Logistical Gradient Descent\n",
        "\n",
        "By Daniel Flynn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sB5tTVrsk5b"
      },
      "source": [
        "A simple description of machine learning would be process of evaluating inputs in order to predict an output. By converting our inputs into numbers and assigning a weight (how much value we consider this particular input to have in our final decision) for each, we arrive at a simple way aggregating everything into our final *conclusion*.\n",
        "\n",
        "A popular technique for determining these weights is Gradient Descent where we can iteratively refine our weights through a process of tweaks intended to minimize the errors of each prediction. We can accomplish this by using a convex function and then finding the local minimum.\n",
        "\n",
        "![Gradient Descent](https://miro.medium.com/max/600/1*iNPHcCxIvcm7RwkRaMTx1g.jpeg)\n",
        "\n",
        "*Source: [Saugat Bhattarai](https://saugatbhattarai.com.np/)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cjbv6GlPvFWh"
      },
      "source": [
        "---\n",
        "\n",
        "## Getting Started\n",
        "\n",
        "Here is a simple model representation. This is over-engineered for most of this assignment but will start to shine with the Iris dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7a-pSIJ9C_l"
      },
      "source": [
        "class Model:\n",
        "  def __init__(self, dimensions, predictFn):\n",
        "    self.dimensions = dimensions\n",
        "    self.data = [uniform(-0.1, 0.1) for i in range(dimensions)] # initialize random weights close to zero\n",
        "    self.predictFn = predictFn\n",
        "\n",
        "  def __getitem__(self, arg):\n",
        "    return self.data[arg]\n",
        "\n",
        "  def __setitem__(self, arg, value):\n",
        "    self.data[arg] = value\n",
        "\n",
        "  def __str__(self):\n",
        "    return str(self.data)\n",
        "\n",
        "  def __iter__(self):\n",
        "    self.current = -1\n",
        "    return self\n",
        "\n",
        "  def __next__(self):\n",
        "    self.current += 1\n",
        "    if self.current < self.dimensions:\n",
        "      return self.data[self.current]\n",
        "    raise StopIteration\n",
        "\n",
        "  def predict(self, input):\n",
        "    return self.predictFn(self.data, input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMTKjHPO9W9X"
      },
      "source": [
        "I'm going with the factory pattern because very little changes between linear and logistical regression and this leads to the most re-usability.\n",
        "\n",
        "As follows is one way of implementing gradient descent:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jA8QJMN_vWtW"
      },
      "source": [
        "%matplotlib inline\n",
        "%load_ext google.colab.data_table\n",
        "\n",
        "# All imports here to make it easier to run each problem piecemeal\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from random import uniform\n",
        "from google.colab import data_table\n",
        "\n",
        "def calculateModelDeltasFactory(convexDerivativeFn):\n",
        "  \"\"\"Generate a model refinement function given the derivative of the convex function for determining the direction the weights need to move to get closer to local minimum\n",
        "\n",
        "  (r: float, p: float) -> float\n",
        "  \"\"\"\n",
        "  def result(outputs, predicted, inputs, dimensions):\n",
        "    dataPoints = len(predicted)\n",
        "\n",
        "    delta = []\n",
        "    for i in range(dimensions):\n",
        "      d = 1/dataPoints * sum([convexDerivativeFn(r, p) * x[i] for r, p, x in zip(outputs, predicted, inputs)])\n",
        "      delta.append(d)\n",
        "    \n",
        "    return delta\n",
        "\n",
        "  return result\n",
        "\n",
        "def problemSolverFactory(\n",
        "    predictFn, # receives the model and inputs\n",
        "    convexFn, # Error function\n",
        "    convexDerivativeFn, # derivative of error function\n",
        "    learningRate = 0.01, # This value is multiplied by the weight deltas during refinement. Too big and the model doesn't converge, too small and it takes forever\n",
        "    learningThreshhold = 0.001 # When the RATE of error loss becomes less than this value the model is returned\n",
        "):\n",
        "  calculateModelDeltas = calculateModelDeltasFactory(convexDerivativeFn)\n",
        "\n",
        "  def result(\n",
        "      inputs, # [ (x0, x1, ...), ... ]\n",
        "      outputs # [ output0, output1, ... ]\n",
        "  ):\n",
        "    dimensions = len(inputs[0])\n",
        "    model = Model(dimensions, predictFn)\n",
        "\n",
        "    last_error = 0\n",
        "    error = float('inf')\n",
        "    iterations = 0\n",
        "\n",
        "    while last_error - error > learningThreshhold or math.isinf(error):\n",
        "      last_error = error;\n",
        "\n",
        "      predictions = [model.predict(i) for i in inputs] # one predicted value for each input of training data\n",
        "      error = sum([ convexFn(r, p) for r, p in zip(outputs, predictions) ]) # ONE value encompassing the entirety of our model's error\n",
        "      deltas = calculateModelDeltas(outputs, predictions, inputs, dimensions) # one derivative value per weight of our model\n",
        "      for i in range(dimensions):\n",
        "        model[i] = model[i] - learningRate * deltas[i]  # w0 = w0 - learningRate * Î”w0, etc...\n",
        "\n",
        "      iterations += 1\n",
        "\n",
        "    if error > last_error: # Error was increasing\n",
        "      raise Exception('Model not converging')\n",
        "\n",
        "    return {\n",
        "        'model': model,\n",
        "        'iterations': iterations\n",
        "    }\n",
        "\n",
        "  return result\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tozBJBsSAqXh"
      },
      "source": [
        "We now have enough boiler plate to dive into each problem set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqNgRRawDoZU"
      },
      "source": [
        "---\n",
        "\n",
        "## Linear Regression\n",
        "\n",
        "The heart of this process is the linear sum:\n",
        "\n",
        "$\\sum_{i=0}^{d} w_{i} * x_{i}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i87jF4ZaCN_9"
      },
      "source": [
        "def linearSum(model, inputs):\n",
        "  \"\"\"Accepts weights and inputs and multiplies each pair together and returns the sum\n",
        "\n",
        "  The dimensions of model and inputs must be identical\n",
        "  \"\"\"\n",
        "  return sum([w*x for w,x in zip(model, inputs)]) # w0*x0 + w1*x1 +...\n",
        "\n",
        "linearSolver = problemSolverFactory(\n",
        "    linearSum,\n",
        "    lambda r, p: (r - p)**2, # squared error\n",
        "    lambda r, p: -2 * (r - p)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB4NKZrGFkoQ"
      },
      "source": [
        "We also want to plot visually how well our model turned out:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05zcw5yFFso-"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plotLinear(inputs, outputs, model):\n",
        "  x = [i[1] for i in inputs]\n",
        "  predicted = [linearSum(model, i) for i in inputs]\n",
        "\n",
        "  plt.plot(x, outputs, \"g+\")\n",
        "  plt.plot(x, predicted, \"b\")\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEc144r8FWGh"
      },
      "source": [
        "#### Noiseless data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvaqFaZGFh_k"
      },
      "source": [
        "data = [((1, -2), 1), ((1, -1), 3), ((1, 0), 5), ((1, 1), 7), ((1, 2), 9), ((1, 3), 11), ((1, 4), 13), ((1, 5), 15), ((1, 6), 17), ((1, 7), 19), ((1, 8), 21), ((1, 9), 23), ((1, 10), 25)]\n",
        "inputs, outputs = [list(i) for i in zip(*data)] # unzip data\n",
        "\n",
        "solution = linearSolver(inputs, outputs)\n",
        "print('Model = ', solution['model'])\n",
        "print('Iterations = ', solution['iterations'])\n",
        "plotLinear(inputs, outputs, solution['model'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uH7PQswEHYr7"
      },
      "source": [
        "#### Noisy data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpyi-5shHbdv"
      },
      "source": [
        "data = [((1, -2), 6.39), ((1, -1), 16.51), ((1, 0), -3.11), ((1, 1), 10.79), ((1, 2), 11.62), ((1, 3), 23.24), ((1, 4), 18.27), ((1, 5), 27.58), ((1, 6), 22.21), ((1, 7), 5.12), ((1, 8), 8.86), ((1, 9), 10.69), ((1, 10), 14.82)]\n",
        "inputs, outputs = [list(i) for i in zip(*data)] # unzip data\n",
        "\n",
        "solution = linearSolver(inputs, outputs)\n",
        "print('Model = ', solution['model'])\n",
        "print('Iterations = ', solution['iterations'])\n",
        "plotLinear(inputs, outputs, solution['model'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxOHZeex-xmL"
      },
      "source": [
        "---\n",
        "\n",
        "## Logistical Regression\n",
        "\n",
        "Logistical regression is similar to linear regression but is used primarily for classification operations. This is accomplished by passing the linear sum into a sigmoid function to fix the output into a range from 0 to 1 non-inclusive. The closer the value is to 0 or 1 the more confident the algorithm is in it's prediction.\n",
        "\n",
        "$sigmoid(x) = \\frac{1}{1 + e^{-x}}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikEmjErEMRT5"
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + math.e ** (-x))\n",
        "\n",
        "logisticSolverSquaredError = problemSolverFactory(\n",
        "    lambda model, inputs: sigmoid(linearSum(model, inputs)),\n",
        "    lambda r, p: (r - p)**2, # squared error\n",
        "    lambda r, p: -2 * (r - p)            *    p * (1 - p)\n",
        "    #            Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯            *    Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯\n",
        "    #    derivative of squared error     *    derivative of sigmoid\n",
        ")\n",
        "\n",
        "logisticSolverCrossEntropy = problemSolverFactory(\n",
        "    lambda model, inputs: sigmoid(linearSum(model, inputs)),\n",
        "    lambda r, p: -math.log(p) if r == 1 else -math.log(1 - p), # cross entropy\n",
        "    lambda r, p: p - r,\n",
        "    learningRate = 0.005\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHnHI8c99zHo"
      },
      "source": [
        "#### Plot Helpers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZrHcA14PZWf"
      },
      "source": [
        "Just like with linear regression, we would also like to plot how our model is doing. Unlike our above linear regression problems though, we have more inputs and must do a bit more work to make it presentable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2_7p448Px_e"
      },
      "source": [
        "def plotLogistic(\n",
        "    inputs,\n",
        "    outputs,\n",
        "    model\n",
        "):\n",
        "  \"\"\"Hardcoded for a 3 weight model\"\"\"\n",
        "  x1Pos = []\n",
        "  x2Pos = []\n",
        "  x1Neg = []\n",
        "  x2Neg = []\n",
        "  x1Min = float('inf')\n",
        "  x1Max = float('-inf')\n",
        "\n",
        "  for i in range(len(outputs)):\n",
        "    if outputs[i] == positive:\n",
        "      x1Pos.append(inputs[i][1])\n",
        "      x2Pos.append(inputs[i][2])\n",
        "    else:\n",
        "      x1Neg.append(inputs[i][1])\n",
        "      x2Neg.append(inputs[i][2])\n",
        "\n",
        "    x1Min = min(x1Min, inputs[i][1])\n",
        "    x1Max = max(x1Max, inputs[i][1])\n",
        "\n",
        "  x1Line = []\n",
        "  i = x1Min\n",
        "  while i < x1Max:\n",
        "    x1Line.append(i)\n",
        "    i += 1\n",
        "  x1Line.append(i)\n",
        "\n",
        "  plt.plot(x1Pos, x2Pos, 'go')\n",
        "  if showNeg:\n",
        "    plt.plot(x1Neg, x2Neg, 'ro')\n",
        "\n",
        "  x2Line = []\n",
        "  for i in x1Line:\n",
        "    x2Line.append((-model[0] / model[2]) - (model[1] / model[2]) * i)\n",
        "\n",
        "  plt.plot(x1Line, x2Line, 'b')\n",
        "  if show:\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C42GontTPMSV"
      },
      "source": [
        "#### Training Data 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDdmvM_MPX5u"
      },
      "source": [
        "data  = [((1, 0, 0), 1), ((1, 1, 7), 0), ((1, -3, -2), 0), ((1, 8, 9), 1), ((1, 4, 3), 1), ((1, 5, -2), 1), ((1, 0, 0), 1), ((1, 6, 9), 1), ((1, 4, 2), 1), ((1, 1, -9), 1), ((1, -7, 7), 0), ((1, 0, -1), 1), ((1, 9, -4), 1), ((1, 1, 0), 1), ((1, -2, -5), 1), ((1, 2, 3), 1), ((1, -7, 2), 0), ((1, -3, 0), 0), ((1, 5, 0), 1), ((1, 0, -3), 1), ((1, -2, 3), 0), ((1, 9, 6), 1), ((1, 0, -8), 1), ((1, 0, 2), 0), ((1, -8, 6), 0), ((1, 1, 9), 0), ((1, 0, 5), 0), ((1, -4, 9), 0), ((1, 8, 2), 1), ((1, 2, 6), 0)]\n",
        "inputs, outputs = [list(i) for i in zip(*data)] # unzip data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyuIhZOfZAzc"
      },
      "source": [
        "##### Squared Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6s41TtxZFOb"
      },
      "source": [
        "solution = logisticSolverSquaredError(inputs, outputs)\n",
        "print('Model = ', solution['model'])\n",
        "print('Iterations = ', solution['iterations'])\n",
        "plotLogistic(inputs, outputs, solution['model'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGwYpxE9eSa8"
      },
      "source": [
        "##### Cross Entropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3a__hyfeVRT"
      },
      "source": [
        "solution = logisticSolverCrossEntropy(inputs, outputs)\n",
        "print('Model = ', solution['model'])\n",
        "print('Iterations = ', solution['iterations'])\n",
        "plotLogistic(inputs, outputs, solution['model'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f76EZDmkmzkc"
      },
      "source": [
        "#### Training Data 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1soPKBLpm6QP"
      },
      "source": [
        "data = [((1, 0, 0), 0), ((1, 1, 7), 0), ((1, -3, -2), 0), ((1, 8, 9), 1), ((1, 4, 3), 1), ((1, 5, -2), 1), ((1, 0, 0), 0), ((1, 6, 9), 1), ((1, 4, 2), 1), ((1, 1, -9), 1), ((1, -7, 7), 0), ((1, 0, -1), 1), ((1, 9, -4), 1), ((1, 1, 0), 1), ((1, -2, -5), 1), ((1, 2, 3), 1), ((1, -7, 2), 0), ((1, -3, 0), 0), ((1, 5, 0), 1), ((1, 0, -3), 1), ((1, -2, 3), 0), ((1, 9, 6), 1), ((1, 0, -8), 1), ((1, 0, 2), 1), ((1, -8, 6), 0), ((1, 1, 9), 0), ((1, 0, 5), 0), ((1, -4, 9), 0), ((1, 8, 2), 1), ((1, 2, 6), 0)]\n",
        "inputs, outputs = [list(i) for i in zip(*data)] # unzip data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcUNlqW9m961"
      },
      "source": [
        "##### Squared Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaG2mdPLnGiH"
      },
      "source": [
        "solution = logisticSolverSquaredError(inputs, outputs)\n",
        "print('Model = ', solution['model'])\n",
        "print('Iterations = ', solution['iterations'])\n",
        "plotLogistic(inputs, outputs, solution['model'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okNa2RDynjxu"
      },
      "source": [
        "##### Cross Entropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A81nvZbrnm-_"
      },
      "source": [
        "solution = logisticSolverCrossEntropy(inputs, outputs)\n",
        "print('Model = ', solution['model'])\n",
        "print('Iterations = ', solution['iterations'])\n",
        "plotLogistic(inputs, outputs, solution['model'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLd4imDcoEqr"
      },
      "source": [
        "#### Training Data 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H31pAEg4oG76"
      },
      "source": [
        "data = [((1, 2, 7), 0), ((1, 19, 72), 0), ((1, -39, -20), 0), ((1, 86, 95), 1), ((1, 45, 37), 1), ((1, 52, -23), 1), ((1, -8, -8), 0), ((1, 67, 93), 1), ((1, 46, 21), 1), ((1, 18, -97), 1), ((1, -78, 70), 0), ((1, -9, -17), 1), ((1, 94, -40), 1), ((1, 11, -3), 1), ((1, -24, -59), 1), ((1, 25, 33), 1), ((1, -71, 23), 0), ((1, -34, -7), 0), ((1, 55, -3), 1), ((1, -5, -33), 1), ((1, -22, 38), 0), ((1, 94, 66), 1), ((1, 4, -89), 1), ((1, -9, 26), 0), ((1, -83, 61), 0), ((1, 19, 98), 0), ((1, -1, 55), 0), ((1, -43, 90), 0), ((1, 86, 27), 1), ((1, 24, 69), 0)]\n",
        "inputs, outputs = [list(i) for i in zip(*data)] # unzip data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMAQkAhKoLu3"
      },
      "source": [
        "##### Squared Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhKBCiCGoNk1"
      },
      "source": [
        "solution = logisticSolverSquaredError(inputs, outputs)\n",
        "print('Model = ', solution['model'])\n",
        "print('Iterations = ', solution['iterations'])\n",
        "plotLogistic(inputs, outputs, solution['model'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xESBs-_n2Mt"
      },
      "source": [
        "##### Cross Entropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qLm2G5_n47w"
      },
      "source": [
        "solution = logisticSolverCrossEntropy(inputs, outputs)\n",
        "print('Model = ', solution['model'])\n",
        "print('Iterations = ', solution['iterations'])\n",
        "plotLogistic(inputs, outputs, solution['model'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usujPcbXobPF"
      },
      "source": [
        "#### Training Data 4 (Iris dataset)\n",
        "\n",
        "This dataset contains more than 2 classifications. This will require a model per classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPtA09jgojA_"
      },
      "source": [
        "Importing data from GitHub:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O33Yls19-nSo"
      },
      "source": [
        "import pandas as pd\n",
        "from enum import Enum\n",
        "\n",
        "class IrisEnum(Enum):\n",
        "  setosa = 0\n",
        "  versicolor = 1\n",
        "  virginica = 2\n",
        "\n",
        "iris_data = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/danny1461/CSCI-191T-Machine-Learning/main/iris.data.csv',\n",
        "    names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'classification']\n",
        ")\n",
        "\n",
        "inputs = iris_data.iloc[:, 0:4].values.tolist()\n",
        "outputs = [IrisEnum[n].value for n in iris_data['classification']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oHWMW7Br-nM"
      },
      "source": [
        "Some helpers to handle the multi-model results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p10nA5UYsDx_"
      },
      "source": [
        "def solveIris(solverFn):\n",
        "  models = []\n",
        "\n",
        "  for i in IrisEnum:\n",
        "    classOutputs = [(1 if o == i.value else 0) for o in outputs]\n",
        "    solution = solverFn(inputs, classOutputs)\n",
        "    models.append(solution['model'])\n",
        "    print('{} Model = {}'.format(i.name, solution['model']))\n",
        "    print('    Iterations = ', solution['iterations'])\n",
        "\n",
        "  plt.show()\n",
        "  return models\n",
        "\n",
        "def classifyIris(input, models):\n",
        "  predictions = [model.predict(input) for model in models]\n",
        "  bestGuess = max(predictions)\n",
        "  bestGuessClass = predictions.index(bestGuess)\n",
        "\n",
        "  return IrisEnum(bestGuessClass)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-O4TWqQroKI"
      },
      "source": [
        "##### Squared Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akW4Z4hhrrAx"
      },
      "source": [
        "models = solveIris(logisticSolverSquaredError)\n",
        "iris_data['predicted'] = [ classifyIris(input, models).name for input in inputs ]\n",
        "data_table.DataTable(iris_data, num_rows_per_page=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r29c16hGn6Bf"
      },
      "source": [
        "##### Cross Entropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1COCPrS1n8qe"
      },
      "source": [
        "models = solveIris(logisticSolverCrossEntropy)\n",
        "iris_data['predicted'] = [ classifyIris(input, models).name for input in inputs ]\n",
        "data_table.DataTable(iris_data, num_rows_per_page=10)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}